<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="PAPER_TITLE - AUTHOR_NAMES">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="FIRST_AUTHOR_NAME, SECOND_AUTHOR_NAME">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>PAPER_TITLE - AUTHOR_NAMES | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- MathJax for mathematical notation -->
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">Active Exploration beyond System Identification</h1>
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                Nikita Maurer</span><br>
                Supervised by Gabriele Tiboni</span>
                <!--<span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Gabriele Tiboni</a><sup>*</sup>,</span>
                  </div>-->

                 <div class="is-size-5 publication-authors">
                    <!-- TODO: Replace with your institution and conference/journal info -->
                    <span class="author-block">Department of Computer Science<br>Technische Universität Darmstadt, Germany</span>
                    <!-- TODO: Remove this line if no equal contribution -->
                    <!--<span class="eql-cntrb"><small><br><sup>*</sup>Supervised by Gabriele Tiboni</small></span>-->
                  </div>
                
                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- TODO: Replace with your teaser video -->
      IMAGE
      <!-- TODO: Replace with your video description -->
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract-->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this project we only consider Simulation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Introduction -->
<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            Robotic learning in simulation has become an indispensable tool for accelerating research and reducing costs before deployment in the real world <a href="#dr" class="citation">[1]</a>. 
            Training in simulation provides safety, scalability, and access to large amounts of interaction data. However, the policies that perform well in simulation often degrade significantly once transferred to real 
            robots - a challenge commonly referred to as the reality gap <a href="#ref2" class="citation">[2]</a>. This gap arises from mismatches between the simplified models used in simulation and the complex, noisy dynamics 
            of physical systems. <br>
          
            A major line of research in sim-to-real transfer focuses on mitigating this gap. Two prominent strategies are Domain Randomization (DR) <a href="#ref3" class="citation">[3]</a> and System 
            Identification (SI) <a href="#ref4" class="citation">[4]</a>. DR aims to expose policies to a wide variety of randomized environments during training, encouraging robustness to unseen real-world conditions. 
            SI, on the other hand, attempts to explicitly identify the dynamics of the target system, either before or during deployment, and adjust the simulation parameters accordingly. While DR offers generalization at the 
            expense of sample efficiency, SI provides more targeted adaptation but often suffers from insufficient or uninformative data for accurate identification. <br>
          
            The ASID (Active exploration for System Identification in robotic manipulation) framework <a href="#ref5" class="citation">[5]</a> addresses this limitation by proposing methods for actively selecting exploratory 
            behaviors that maximize information about unknown system parameters. Rather than passively collecting data or relying on heuristic exploration, ASID leverages an optimization criterion based on Fisher Information to 
            generate trajectories that are maximally informative for system identification. This approach aims to make SI more efficient and reliable, ultimately improving sim-to-real transfer in robotic manipulation tasks. <br>
          </p>
          <p>
            Beyond system identification, such objectives resonate with the broader idea of curiosity-driven exploration - encouraging robots to explore their environment without being explicitly told what to 
            do <a href="#ref6" class="citation">[6]</a>. One reason this can be extremely useful is acquiring general-purpose behaviors to accelerate the learning of new downstream tasks. Instead of training from scratch for every 
            new objective, agents can benefit 
            from a repertoire of skills - temporally extended action patterns that serve as primitives for hierarchical reinforcement learning <a href="#ref8" class="citation">[8]</a>. The paper "Diversity is All You Need" 
            (DIAYN) <a href="#ref9" class="citation">[9]</a> introduced the idea of unsupervised skill discovery, where an agent learns a diverse set of behaviors without requiring an external reward function. These unsupervised 
            skills not only provide a foundation for faster task learning but also enhance exploration in environments with sparse or delayed rewards, and can support applications such as imitation learning and transfer across related 
            tasks <a href="#ref10" class="citation">[10]</a>.<br>
          </p>
          
          <div class="multi-images-full-width">
            <div class="images-container">
              <div class="image-container">
                <img src="static/images/diayn/diayn_clip13.mov.gif" alt="First result" loading="lazy"/>
              </div>
              <div class="image-container">
                <img src="static/images/diayn/diayn_clip10.mov.gif" alt="First result" loading="lazy"/>
              </div>
              <div class="image-container">
                <img src="static/images/diayn/diayn_clip18.mov.gif" alt="First result" loading="lazy"/>
              </div>
              <div class="image-container">
                <img src="static/images/diayn/diayn_clip2.mov.gif" alt="First result" loading="lazy"/>
              </div>
              
            </div>
            <p style="text-align: center; font-size: 0.9rem; color: #64748b; margin-top: 1rem; font-style: italic;">
              https://sites.google.com/view/diayn
            </p>
          </div>

          <p>
            However, while DIAYN and its successors demonstrated compelling results in locomotion domains such as cheetah or humanoid agents <a href="#ref11" class="citation">[11,12]</a>, robotic manipulation remains a largely 
            unsolved challenge <a href="#ref13" class="citation">[13]</a>. Current methods struggle to produce diverse and reusable manipulation skills without task-specific supervision, leaving open the question of how to adapt 
            unsupervised exploration principles to this more complex setting.<br>
          </p>
          <p>
            Our project builds on this motivation by seeking to extend the ASID framework beyond system identification. ASID showed how the Fisher Information can guide robots toward collecting trajectories that are informative 
            for parameter inference. We propose to adapt this principle for unsupervised skill discovery: instead of treating the objective as purely about maximizing entropy or covering all parameters equally, we reinterpret simulated 
            parameters as a curiosity signal. By selectively focusing on information along certain parameter axes while ignoring or surpressing others, the agent can discover a richer and more diverse set of skills. 
            This perspective opens the door to curiosity-guided skill discovery for robotic manipulation, bridging the gap between system identification for sim-to-real transfer and unsupervised exploration for skill learning.<br>
          </p>
          
          <!-- Lists in main section -->
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Key Contributions</h3>
          <ul style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
            <li>Extension of ASID framework for unsupervised skill discovery in robotic manipulation</li>
            <li>Novel information-theoretic approach to curiosity-driven exploration</li>
            <li>Comprehensive evaluation across multiple manipulation tasks and environments</li>
            <li>Demonstration of improved sim-to-real transfer performance compared to baseline methods</li>
          </ul>
          
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Experimental Validation</h3>
          <ol style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
            <li>Simulation experiments with varying physical parameters and task complexities</li>
            <li>Real-world validation on physical robotic manipulation platforms</li>
            <li>Comparison with state-of-the-art domain randomization and system identification methods</li>
            <li>Analysis of skill diversity and transfer performance metrics</li>
            <li>Ablation studies to understand the contribution of each component</li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Background Section with Subsections -->
<!-- <section class="section hero is-light"> -->
<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Background and Related Works</h2>
        <div class="content has-text-justified">

          <!-- Subsection: Simulation-to-Reality Transfer -->
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Simulation-to-Reality Transfer</h3>
          <p>
            Simulators play a central role in robotics because they allow large-scale data generation without physical costs. They enable training of policies in parallel, 
            at accelerated time scales, and with full access to ground-truth state information. Formally, the real-world environment is characterized by 
            dynamics P(TODO) with ture parameters TODO. A simulator provides approximate dynamics TODO Training in simulation corresponds to optimizing policies 
            under, with the hope that they transfer successfully to P.
          </p>

          <p>
            <h3 class="title is-5" style="margin-top: 1rem; margin-bottom: 1rem;">The Sim-to-Real Gap</h3>
            The difference between P is called the Sim-to-Real gap. It arises from:
            <ul style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
              <li><b>Modeling approximations.</b> Physical simulators cannot perfectly capture complex phenomena such as contact friction or deformable objects.</li>
              <li><b>Parameter discrepancies.</b> Even if the model form is correct, simulator parameters such as masses, delays, or sensor noise rarely match reality exactly.</li>
              <li><b>Non-stationarity of real environments.</b> Real-world conditions change over time due to wear, environmental variations, or sensor drift.</li>
            </ul>
            Bridging the Sim2Real gap is essential for deploying RL policies learned in simulation.
          </p>

          <p>
            <h3 class="title is-5" style="margin-top: 1rem; margin-bottom: 1rem;">Domain Randomization</h3>
            A prominent strategy is domain randomization (DR). Introduced by Tobin et al. (2017), DR trains policies on a distribution of simulators 
            with randomized parameters, thereby producing robustness to variations. 
            The intuition is that if the policy succeeds across a wide variety of simulated domains, it is likely to generalize to the real world.
            <ul style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
              <li><b>Tobin et al. (2017).</b> The authors randomized visual properties such as textures, lighting, and object appearances in a vision-based robotic 
                      grasping task. This prevented the policy from overfitting to the simulator's graphics and enabled zero-shot transfer to real images.</li>
              <li><b>Peng et al. (2018).</b> Extended this idea to dynamics randomization, perturbing physical parameters such as masses, friction coefficients, 
                      and actuator delays. Training across this ensemble yielded policies that transferred directly to real quadrupeds, demonstrating the effectiveness of randomizing physics as well as visuals.</li>
              <li><b>DROPO (Tiboni et al.).</b> Recognizing that naive randomization can waste samples on unrealistic domains, DROPO formulates domain randomization 
                      itself as an optimization problem. The algorithm adapts the distribution of randomized parameters to maximize policy learning progress, thereby 
                      improving sample efficiency.</li>
              <li><b>DORAEMON (Tiboni et al.).</b> This approach instead maximizes the entropy of the parameter distribution, ensuring coverage of diverse dynamics. 
                      By emphasizing diversity, DORAEMON enhances robustness to real-world variability</li>
            </ul>
            Domain randomization is powerful but limited by the fidelity of the simulator: if the real world lies outside the span of randomized domains, 
            transfer may still fail.
          </p>

          <p>
            <h3 class="title is-5" style="margin-top: 1rem; margin-bottom: 1rem;">System Identification</h3>
            System Identification (SI) aims to directly align the simulator with reality by estimating physical parameters that make simulated trajectories match 
            real observations. Classical SI techniques require carefully designed excitation trajectories that sufficiently probe the dynamics. 

            Optimization can be performed using gradient-free methods such as CMA-ES, or gradient-based methods when differentiable simulators are available. <br>
            SI methods typically rely on trajectory matching, where real and simulated trajectories are compared and parameters are adjusted to minimize discrepancies.
            
            Two main strategies can be distinguished:
            <ul style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
              <li><b>Open-loop matching:</b> The real action sequence is replayed in the simulator, and the resulting observations are compared. 
                This is simple and cost-effective, but mismatches can accumulate if the simulator drifts away from the real trajectory. </li>
              <li><b>Closed-loop matching:</b> Both simulator and real system execute the same policy, and discrepancies are measured between the resulting behaviors. 
                This is more robust, but requires the availability of working policies early on.</li>
            </ul>

            A second distinction concerns whether adaptation is done online or offline:
            <ul style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
              <li><b>Online methods:</b> alternate between simulation and real-world rollouts, continuously updating the parameter distribution. This makes them adaptive 
                but also dependent on the quality of the current policy. </li>
              <li><b>Offline methods:</b> use fixed datasets of real trajectories. They avoid repeated deployments but may suffer if real trajectories 
                cannot be reliably reproduced in simulation.</li>
            </ul>
            Tiboni et al. (2022) compared online and offline methods across benchmarks. TODO ref

            Recent work illustrates these categories. SimOpt (Chebotar et al., 2019) is an online, closed-loop approach that updates parameter distributions after comparing simulated 
            and real rollouts of the same policy. BayRn (Muratore et al., 2021) combines domain randomization with Bayesian optimization, adapting parameter distributions based on 
            sparse real-world feedback. DROID (Tsai et al., 2021) aligns simulator parameters with human demonstrations in an offline, open-loop manner. DROPO (Tiboni et al., 2022) 
            also works offline, using real trajectories to adjust parameter distributions by replaying them in simulation.
          </p>

          <p>
            <h3 class="title is-5" style="margin-top: 1rem; margin-bottom: 1rem;">Active Exploration for System Identification (ASID)</h3>
            ASID reframes SI as an active exploration problem. Instead of relying on hand-designed excitation signals, ASID trains exploration policies that maximize the 
            Fisher information about unknown dynamics parameters. The Fisher Information Matrix (FIM) for parameter $\phi$ under trajectory distribution TODO is defined as
            TODO
            Maximizing the determinant or trace of I(ϕ) ensures that the resulting data are maximally informative for parameter estimation.
            ASID exhibits that exploratory policies trained in simulation often transfer well to reality, even when task policies do not. 
            By decoupling exploration from exploitation, ASID enables robots to collect informative trajectory in the real world that can then be used to refine the 
            simulator and learn downstream task policies. This represents a synthesis of classical SI with modern RL-based exploration. <br>
            
            ASID pipeline consists of three tightly connected stages:
            <ul style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
            <li><b>Exploration:</b> An exploration policy π_exp is trained in simulation with the explicit goal of maximizing the Fisher information of the resulting 
              trajectories. This ensures that actions taken in the real system will be maximally informative for distinguishing underlying dynamics parameters. 
              Importantly, training is done purely in simulation, exploiting abundant and inexpensive synthetic rollouts</li>
            <li><b>System Identification:</b> The learned exploration policy is executed on the real robot to collect informative trajectories. These data are then used 
              in a system identification step, which estimates key simulation parameters such as inertial properties, friction coefficients, or kinematic configurations. 
              By reducing model mismatch, the updated simulator provides a more accurate substrate for downstream learning</li>
            <li><b>Policy Optimization and Transfer:</b> With the refined simulator in place, a task-specific policy πtask is trained using standard reinforcement 
              learning. Finally the trained policy can be deployed zero-shot in the real world. i.e., without requireing further adaptation. </li>
            </ul>
            
          </p>

          <div style="text-align: center; margin: 2rem 0;">
            <img src="static/images/asid/asid_method.png" alt="Exploration policy" style="max-width: 100%; height: auto; border-radius: 12px;"/>
            <p style="text-align: center; font-size: 0.9rem; color: #64748b; margin-top: 1rem; font-style: italic;">
              Overview of ASID pipeline by authors: https://weirdlabuw.github.io/asid/
            </p>
          </div>


          <!-- Subsection: Skill Discovery -->
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Unsupervised RL and Skill Discovery</h3>
          
          <p>
            <h3 class="title is-5" style="margin-top: 1rem; margin-bottom: 1rem;">Unsupervised Reinforcement Learning</h3>
            Unsupervised reinforcement learning (URL) aims to pretrain agents without external task rewards by relying on intrinsic objectives that encourage broad 
            exploration and the discovery of diverse behaviors. Instead of optimizing a single extrinsic return, the agent seeks to acquire skills or representations 
            that can later accelerate downstream task learning, reduce sample complexity, or support zero-shot transfer. This paradigm is particularly appealing in robotics, 
            where task-specific rewards are expensive to design and real-world interactions are costly or unsafe. The central challenge is defining intrinsic signals 
            that produce both diverse and useful behaviors, rather than uncontrolled exploration.
          </p>

          <p>
            <h3 class="title is-5" style="margin-top: 1rem; margin-bottom: 1rem;">Unsupervised Skill Discovery</h3>
            A dominant line of work formulates skill discovery as maximizing the mutual information between latent skill variables and the resulting state distributions, 
            implemented with discriminators that predict skills from observed trajectories. Early work such as Variational Intrinsic Control (Gregor et al., 2016) and 
            Diversity Is All You Need (Eysenbach et al., 2019) showed that a latent-conditioned policy can be trained to produce distinct, repeatable behaviors purely 
            through information-theoretic objectives. Extensions like Dynamics-Aware Discovery of Skills (Sharma et al., 2020) incorporate learned dynamics models to bias 
            skills toward predictable and physically consistent interactions, which is particularly relevant for manipulation. Other approaches maximize state coverage 
            directly (Hazan et al., 2019; Lee et al., 2019), or employ novelty- and prediction-based intrinsic motivation (Pathak et al., 2017; Burda et al., 2019), 
            but broad coverage alone does not guarantee that learned skills are semantically meaningful or composable.<br>
            
            These advances demonstrate the feasibility of acquiring reusable primitives in simulation, and applications have been reported in locomotion 
            (Eysenbach et al., 2019), hierarchical RL (Nachum et al., 2018), and robotic manipulation (Sharma et al., 2020; Pertsch et al., 2021). However, 
            key challenges remain: unsupervised objectives often require large numbers of interactions, and ensuring sample efficiency and safety in real robots 
            is nontrivial. Moreover, skills discovered through diversity maximization may not align with downstream tasks, and their transfer from simulation to the 
            real world is complicated by modeling errors and partial observability. Addressing these gaps requires incorporating task relevance, grounding in robot 
            dynamics, and sim-to-real adaptation mechanisms—directions that motivate integrated frameworks such as active system identification.
          </p>
          
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Re-Implementing ASID -->
<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Re-Implementing ASID</h2>
        <div class="content has-text-justified">
          
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Exploration</h3>
          <p>
            For the exploration stage, we directly rely on the publicly available ASID exploration module provided by the original authors. (TODO) 
            The exploration module is implemented in Python and makes use of the Soft Actor-Critic (SAC) algorithm together with vectorized Mujoco environments, which enables efficient parallel trainign.

            The objective of exploration in ASID is to collect trajectories that are maximally informative about the system's unknown physical parameters. 
            This is formalized through the notion of Fisher information, which measures how sensitive the system's next states are to variations in these parameters. 
            Policies trained under this objective naturally seek out states where the dynamics are most affected by parameter changes, thereby producing observations that support accurate system identification later on.
          
            In practice, the authors identify three key challenges in making this objective workable:
            <ol style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
              <li><em>Complexity of the information measure.</em> In general, computing Fisher information exactly is intractable. To make the problem solvable, the authors assume a simplified structure of the 
                system dynamics that highlights states where parameter sensitivity is highest. This is realized by applying Gaussian process noise for observations.</li>
              <li><em>Unknown true parameters.</em> Since the actual system parameters are not known during training, the optimization cannot be performed directly. Instead, the method relies on domain randomization, 
                training policies against a distribution of possible parameters rather than a single fixed value. This approximation is sufficient to yield effective exploration behaviors in practice.</li>
              <li><em>Non-differentiable simulators.</em> Many physics engines, including Mujoco, do not expose analytical derivatives with respect to system parameters. To address this, the authors approximate 
                parameter sensitivities using finite differences: perturbing parameters slightly in both directions and measuring the effect on the next state.</li>
            </ol>
          </p>

          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">System Identification</h3>
          <p>
            In the system identification phase, our goal is to adapt specific parameters in the simulator, so that it faithfully reproduces the real-world dynamics observed during the exploration phase.
            First, a trajectory $\tau_{\text{real}} \sim p_{\boldsymbol{\theta}}^*( \cdot | \pi_{\text{exp}})$ is collected by executing the learned exploration policy $\pi_{\text{exp}}$ in the real environment. 
            The simulator is then updated such that simulated rollouts align with this reference trajectory. 
            Concretely, the objective is to find a distribution over simulation parameters $\boldsymbol{q}_{\phi}$ that minimizes the expected trajectory mismatch between observations
            <p style="text-align: center;">
              $$ \mathbb{E}_{\boldsymbol{\theta} \sim q_\phi} [ \mathbb{E}_{\tau_{\text{sim}} \sim p_{\boldsymbol{\theta}}( \cdot | \mathcal{A}(\tau_{\text{real}}) )}  [|| \tau_{\text{real}} - \tau_{\text{sim}} ||_2^2] ]$$
            </p>
            where $p_{\boldsymbol{\theta}}(\cdot | \mathcal{A}(\tau_{\text{real}}))$ is the trajectory distribution in the simulator when replaying the exact action sequence from the real trajectory $\tau_{\text{real}}$ (offline).
            This ensures that discrepancies in dynamics are attributed to parameter misspecification, rather than policy mismatch.<br>

            In our reimplementation, we additionally explore a variation of the procedure where trajectory samples are generated by executing the current policy directly (online) 
            instead of replaying the real-world action sequence. This experimental comparison enables us to investigate the trade-off between strict action-replay matching and on-policy identification.<br>
            
            For the trajectory optimization, the ASID framework allows the use of any black-box optimizer. The authors use Relative Entropy Policy Search (REPS) for simulation and Cross Entropy Method (CEM) for the real experiments. 
            In this project, we implement both methods and compare them. <br>
          </p>
          <p>
            <h3 class="title is-5" style="margin-top: 1rem; margin-bottom: 1rem;">Cross Entropy Method</h3>
            CEM is a population-based black-box optimization algorithm. It maintains a Gaussian distribution $q(\theta) = \mathcal{N}(\mu, \sigma^2)$ over parameters $\theta$ and iteratively refines this distribution by 
            focusing on "elite" samples - those with the lowest objective values (or equivalently, highest rewards). Over time, $q$ concentrates around promising regions of the parameter space.

            Hyperparameters include:
            <ol style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
              <li><em>Number of samples $N$.</em> the number of candidate parameter vectors sampled per iteration.</li>
              <li><em>Elite ratio $e$.</em> fraction of samples selected as elites ($N_e = eN$).</li>
              <li><em>Smoothing factor $\alpha$.</em> controls how strongly the new mean/std deviate from the previous iteration.</li>
              <li><em>Number of iterations $T$.</em> number of optimization cycles (termination condition).</li>
            </ol>

            Our implementation proceeds as follows:
            <div class="pseudocode-container">
              <div class="pseudocode-header">
                <h4 class="pseudocode-title">Pseudocode for CEM </h4>
              </div>
              <div class="pseudocode-content">
                <span class="pseudocode-line">Input: objective_fn, initial mean μ0, std σ0</span>
                <span class="pseudocode-line">For iteration = 1 … T:</span>
                <span class="pseudocode-line">    Sample θ1 … θN ~ N(μ, σ^2)</span>
                <span class="pseudocode-line">    Evaluate objectives objectives ← f(θi)</span>
                <span class="pseudocode-line">    Select top (minimum) Ne elite samples</span>
                <span class="pseudocode-line">    Update mean: μ ← α μ + (1-α) mean(elites)</span>
                <span class="pseudocode-line">    Update std:  σ ← α σ + (1-α) std(elites)</span>
                <span class="pseudocode-line">    Enforce minimum σ per parameter (exploration floor)</span>
                <span class="pseudocode-line">Output: final mean μ</span>
              </div>
            </div>

            Note the following implementation details:
            <ol style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
              <li>Following a rule-of-thumb, the initial standard deviation is chosen as $\text{range}/\sqrt{12}$ per parameter, corresponding to the standard deviation of a uniform distribution over the parameter bounds. 
                This ensures that the Gaussian initially covers the parameter space reasonably. </li>
              <li>A minimum variance constraint is enforced to prevent premature collapse of the search distribution.</li>
              <li>Updates to the mean and standard deviation are smoothed using the hyperparameter $\alpha$.</li>
            </ol>
          </p>

          <p>
            <h3 class="title is-5" style="margin-top: 1rem; margin-bottom: 1rem;">Relative Entropy Policy Search</h3>
            Relative Entropy Policy Search (REPS) is an information-theoretic optimization method originally developed for reinforcement learning, but it can be applied generally 
            to black-box optimization problems such as system identification. The central idea is to update a sampling distribution over candidate parameters in such a way that the expected reward is maximized, 
            while constraining the update by a KL-divergence bound. This ensures that updates are stable and avoid premature collapse of the distribution.
            Formally, given a set of sampled rewards $r_i$ REPS solves the constrained optimization problem
          </p>
          <p style="text-align: center;">
          $$\max_q \sum_{i} q_i r_i \text{s.t.} D_{KL}(q || u) \leq \epsilon, \sum_{i} q_i = 1$$
          </p>

          where $u$ is the uniform distribution over samples and $\epsilon > 0$ controls the size of the update. The dual problem introduces a Lagrange multiplier $\eta$, leading to the optimal distribution
          <p style="text-align: center;">
          $$q^*_i \propto \text{exp}(\frac{r_i}{\eta})$$
          </p>

          Thus, the sample weights $w_i$ are given by a normalized exponential tilt of the rewards, where \eta is obtained by minimizing the convex dual
          <p style="text-align: center;">
          $$ g(\eta) = \eta \epsilon + \eta log(\frac{1}{N} \sum_{i=1}^N exp(\frac{r_i}{\eta}))$$
          </p>

          Hyperparameters include:
          <ol style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
              <li><em>$\epsilon$</em> KL-divergence bound controlling update size.</li>
              <li><em>num_sampels</em> num_samples: Number of parameter samples drawn per iteration.</li>
              <li><em>Number of iterations $T$.</em> Number of optimization steps (termination condition).</li>
          </ol>
          
          Our implementation proceeds as follows:
          <div class="pseudocode-container">
              <div class="pseudocode-header">
                <h4 class="pseudocode-title">Pseudocode for REPS </h4>
        </div>
              <div class="pseudocode-content">
                <span class="pseudocode-line">Initialize mean = initial_params</span>
                <span class="pseudocode-line">Initialize covariance from parameter bounds</span>
                <span class="pseudocode-line">samples ← draw num_samples from N(mean, covariance)</span>
                <span class="pseudocode-line">rewards ← - objective_fn(samples)   # negative trajectory mismatch</span>
                <span class="pseudocode-line"></span>
                <span class="pseudocode-line"># Solve dual</span>
                <span class="pseudocode-line">η* ← argmin g(η) using Newton's method</span>
                <span class="pseudocode-line">weights ← softmax(rewards / η*)</span>
                <span class="pseudocode-line"></span>
                <span class="pseudocode-line"># Moment matching update</span>
                <span class="pseudocode-line">mean ← Σ_i w_i * samples[i]</span>
                <span class="pseudocode-line">covariance ← Σ_i w_i * (samples[i] - mean)(samples[i] - mean)^T</span>
                <span class="pseudocode-line"></span>
                <span class="pseudocode-line">return mean</span>
              </div>
            </div>

          Note some implementation details:
          <ol style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
            <li>Similar to CEM, the initial covariance is set to $\text{diag}(\text{range}\sqrt{12})^2$, accoding to parameter ranges.</li>
            <li>Instead of commonly used Broyden-Fletcher-Goldfarb-Shanno method (BFGS), we solve the dual optimization problem with Newton's method, exploiting the closed-form gradient and Hessian of $g(\eta)$ </li>
            <li>To avoid numerical overflow, we use the log-sum-exp trick in the computation of the partition function.</li>
          </ol>
          

          
        <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Rod Balancing Task</h3>
          <p>
            Balancing and stacking objects are canonical tasks in robotic manipulation that critically depend on accurate inertial parameters.
            To evaluate ASID's ability to perform active system identification, the original authors designed a <em>Rod Balancing</em> task. In this setting, the agent interacts with a rod whose internal mass distribution 
            is varied across episodes. The agent must infer the inertial parameters of the rod by probing it through exploratory actions. Once identified, this knowledge is required to solve the downstream task: 
            balancing the rod by placing it on a tower of cubes. It is essential to identify the rods exact center of mass (refered to as inertia) to stabalize it on top. 
            As the focus of our re-implementation lies in reproducing the exploration behavior and verifying its potential for accurate system identification, we do not consider learning the actual balancing task. However, we 
            use the provided simulation environment by the authors.
          </p>

          <p>
            <h3 class="title is-5" style="margin-top: 1rem; margin-bottom: 1rem;">Experimental Setup</h3>
            The simulated Franka Emika Panda robot arm is mounted on a fixed table. According to the applied domain randomization, the placement of the rod is perturbed uniformly within fixed ranges:
            $x = 0.4 \pm 0.1$ meters and $y = 0.3 + 0.1$.
            The rod itself is modeled as a box of dimensions 0.04 $\times$ 0.3 $\times$ 0.04 meters. For exploring, the parameter of interest is the mass distribution 
            (inertia) along the length of the rod, which is uniformly varied within $[-0.1, 0.1]$ for each episode. Therefore,
            we train the exploration policy only w.r.t. to the distribution of mass, but use the resulting policy to infer the inertia and friction parameters of the rod. <br>
          </p>
          
          <p>
            The robot is controlled at the end-effector level. Following the original design, the arm is constrained to operate in the x-y plane, resulting in two degrees of freedom (2-DoF) for the exploration task.
            <ul style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
              <li><b>Action space.</b> The 7 dimensional control signal corresponds to the 7-DoF joint velocities of the Franka arm plus the gripper width. Each dimension is bounded within $[-0.1, 0.1]$.</li>
              <li><b>Observation space.</b> The 22 dimensional observation vector is composed of three components: (1) joint positions of the 7-DoF arm and gripper width, (2) 7-DoF end-effector pose and gripper width, 
                and (3) 7 dimensional rod pose using quaternion orientation. </li>
            </ul>
          </p>
          
          </p>
          <h3 class="title is-5" style="margin-top: 2rem; margin-bottom: 1rem;">Exploration Results</h3>
          <p>
            The exploration policy was trained using Soft Actor-Critic (SAC), with a total of 250,000 timesteps. We used 12 parallel training environments and 4 parallel evaluation environments (~3.5 hours - CPU only). 
            Here, we present a brief training analysis with visualizations of the exploration behavior of the resulting policy.   
          </p>

          <div style="text-align: center; margin: 2rem 0;">
            <img src="static/images/sysid/return_sysid.png" alt="Return curve" style="max-width: 75%; height: auto; border-radius: 12px; box-shadow: 0 10px 15px -3px rgb(0 0 0 / 0.1);"/>
            <p style="text-align: center; font-size: 0.9rem; color: #64748b; margin-top: 1rem; font-style: italic;">
              Return for training exploration policy w.r.t. inertia (center of mass) over 250,000 timesteps.
            </p>
          </div>

          <p>
            Note, rewards are clipped to 1000 and the episode length is fixed to 30 steps. The next animated image gives insight to the learned exploration 
            behavior and resulting reward signal from the inertia information obtained by the movement:
          </p>

          <div style="text-align: center; margin: 2rem 0;">
            <img src="static/images/sysid/inertia_exploration_sysid.gif" alt="Animated Exploration Trajectories" style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 10px 15px -3px rgb(0 0 0 / 0.1);"/>
            <p style="text-align: center; font-size: 0.9rem; color: #64748b; margin-top: 1rem; font-style: italic;">
              Four animated trajectories with corresponding return plots in the final evaluation step of the trained exploration policy. The blue sphere in the rod marks the center of mass. Return corresponds to the Fisher Information of inertia.
            </p>
          </div>

          <p>
            Generally, we can see that the trajectories aim at interaction. Although the center of mass marked by the blue sphere is unknown to the agent, 
            we can observe that the gripper seems to target it to prevent losig contact with the rod.
          </p>

          <p>
            Finally, we analyze the network losses: The decreasing actor loss (policy network) suggests that the policy is improving its action selection and becoming 
            more optimal over time. However, the increasing critic loss (value network) is having difficulty approximating the value function accurately. 
            We have noticed this in other settings as well, but at the same time, we find that the policy still reflects a plausible exploration capability.
          </p>
          
          <div class="multi-images-layout">
            <div class="image-container">
              <img src="static/images/sysid/actor_loss_sysid.png" alt="First step image" loading="lazy"/>
              <p class="image-caption">Plot of actor loss during the training of the exploration policy.</p>
            </div>
            <div class="image-container">
              <img src="static/images/sysid/critic_loss_sysid.png" alt="Second step image" loading="lazy"/>
              <p class="image-caption">Plot of critic loss during the training of the exploration policy.</p>
            </div>
          </div>

          </p>
          <h3 class="title is-5" style="margin-top: 2rem; margin-bottom: 1rem;">System Identification Results</h3>
          <p>
            In this section, we present the results optained from the system idenfication, specifically inertia and friction, based on the previously learned 
            exploration policy. 
            
            To emulate the real-world trajectory we seperately configure a simulator. The real and initial simulation parmeters compared with their parameter ranges 
            used for DR during exploration and here, for initialization of the optimizers (std/cov) are the following:
            <ul style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
              <li><b>Real</b> [inertia, friction]: [-0.1, 1.0] - rods center of mass is on the left side and the rod has low friction.</li>
              <li><b>Initial</b> [inertia, friction]: [0.1, 3.0] - rods center of mass is on the right side and the rod has high friction.</li>
              <li><b>Ranges:</b> inertia [-0.1, 0.1], friction [1.0, 3.0]</li>
            </ul>
          
            This initialization creates a significant discrepancy, requiring the optimizer to recover the correct dynamics.
          </p>

          <p>
            We apply CEM and REPS. For each method, we evaluate the two modes:
            <ul style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
              <li><b>Offline</b> mode follows the ASID framework, the optimizer replays the action sequence of the real trajectory when generating simulated rollouts.</li>
              <li><b>Online</b> mode introduced here as an experimental variation, the optimizer instead generates rollouts by executing the current policy.</li>
            </ul>
          </p>
          
          The used hyperparameters for the optimizers are listed in the following tables:

          <div style="overflow-x: auto; margin: 2rem 0;">
            <table class="table is-bordered is-striped is-fullwidth" style="margin: 0 auto;">
              <thead>
                <tr style="background-color: #f8fafc;">
                  <th style="text-align: center; font-weight: 600;">Optimizer</th>
                  <th style="text-align: center; font-weight: 600;">Iterations</th>
                  <th style="text-align: center; font-weight: 600;">Samples</th>
                  <th style="text-align: center; font-weight: 600;">Elite Ratio</th>
                  <th style="text-align: center; font-weight: 600;">Alpha</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align: center; font-weight: 500;">CEM</td>
                  <td style="text-align: center;">25</td>
                  <td style="text-align: center;">96</td>
                  <td style="text-align: center;">0.2</td>
                  <td style="text-align: center;">0.3</td>
                </tr>
              </tbody>
            </table>
          </div>

          <div style="overflow-x: auto; margin: 2rem 0;">
            <table class="table is-bordered is-striped is-fullwidth" style="margin: 0 auto;">
              <thead>
                <tr style="background-color: #f8fafc;">
                  <th style="text-align: center; font-weight: 600;">Optimizer</th>
                  <th style="text-align: center; font-weight: 600;">Iterations</th>
                  <th style="text-align: center; font-weight: 600;">Samples</th>
                  <th style="text-align: center; font-weight: 600;">Epsilon</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align: center; font-weight: 500;">REPS</td>
                  <td style="text-align: center;">25</td>
                  <td style="text-align: center;">96</td>
                  <td style="text-align: center;">0.1</td>
                </tr>
              </tbody>
            </table>
          </div>



          We present the objective values representing the observation missmatch (L2) between the targeted "real" trajectory and optimized trajectoriy: 

          <div style="text-align: center; margin: 2rem 0;">
            <img src="static/images/sysid/optimization_history.png" alt="Exploration policy" style="max-width: 60%; height: auto; border-radius: 12px; box-shadow: 0 10px 15px -3px rgb(0 0 0 / 0.1);"/>
            <p style="text-align: center; font-size: 0.9rem; color: #64748b; margin-top: 1rem; font-style: italic;">
              High-level system architecture showing the integration of active exploration, skill discovery, and sim-to-real transfer components
            </p>
          </div>
          
          <p>
            Based on this experiment, we find that our REPS variants are both able to reduce the trajectory missmatch nearly perfectly. Although the offline version 
            required less iterations to convergence, we can confirm both are suited for ASID. However, the CEM methods do not perform at all. We tested different 
            conservation rations for the alpha update of the standard deviation to prevent premature narrowing, but could not find a suited configuration. Therefore, 
            we don't want to exclude the possibility that this is an implementation error.
          </p>

          <p>
            Next, we can analyze the parameter evoluations:
          </p>

          <div style="text-align: center; margin: 2rem 0;">
            <img src="static/images/sysid/parameter_history.png" alt="Exploration policy" style="max-width: 85%; height: auto; border-radius: 12px; box-shadow: 0 10px 15px -3px rgb(0 0 0 / 0.1);"/>
            <p style="text-align: center; font-size: 0.9rem; color: #64748b; margin-top: 1rem; font-style: italic;">
              High-level system architecture showing the integration of active exploration, skill discovery, and sim-to-real transfer components
            </p>
          </div>
          
          <p>
            Again, we oberve the obvious performance difference between REPS and CEM variants. Interestingly, CEM's parameter evolutions for friction suggest slight improvement. 
            Generally, the inertia parameter seems to be inferable more accurately by the REPS variants compared to friction. This is likely due to the exploration policy beeing 
            explicitely targeted to maximize inertial sensitivity. 
          </p>

          <p>
            Finally, we show visual results of trajectories optimized using offline variants of CEM and REPS. We show trajectories after 0 (initial), 10 (intermediate), and 25 (final) optimization iterations 
            compared to the targeted "real" trajectory:
          </p>

          <div class="multi-images-layout">
            <div class="image-container">
              <img src="static/images/sysid/cem/cem_offline_init_right.gif" alt="First step image" loading="lazy"/>
              <p class="image-caption">Initial (0)</p>
            </div>
            <div class="image-container">
              <img src="static/images/sysid/cem/cem_offline_10_right.gif" alt="First step image" loading="lazy"/>
              <p class="image-caption">Intermediate (10)</p>
            </div>
            <div class="image-container">
              <img src="static/images/sysid/cem/cem_offline_final_right.gif" alt="First step image" loading="lazy"/>
              <p class="image-caption">Final (25)</p>
            </div>
            <div class="image-container">
              <img src="static/images/sysid/real_left.gif" alt="First step image" loading="lazy"/>
              <p class="image-caption">Real</p>
            </div>
            <p style="text-align: center; font-size: 0.9rem; color: #64748b; margin-top: -2.5rem; font-style: italic;">
              Compares trajectories optimized using offline <b>CEM</b> after 0, 10, and 25 iterations compared to the real trajectory.
            </p>
          </div>

          <div class="multi-images-layout">
            <div class="image-container">
              <img src="static/images/sysid/reps/reps_offline_init_right.gif" alt="First step image" loading="lazy"/>
              <p class="image-caption">Initial (0)</p>
            </div>
            <div class="image-container">
              <img src="static/images/sysid/reps/reps_offline_10_right.gif" alt="First step image" loading="lazy"/>
              <p class="image-caption">Intermediate (10)</p>
            </div>
            <div class="image-container">
              <img src="static/images/sysid/reps/reps_offline_final_right.gif" alt="First step image" loading="lazy"/>
              <p class="image-caption">Final (25)</p>
            </div>
            <div class="image-container">
              <img src="static/images/sysid/real_left.gif" alt="First step image" loading="lazy"/>
              <p class="image-caption">Real</p>
            </div>
            <p style="text-align: center; font-size: 0.9rem; color: #64748b; margin-top: -2.5rem; font-style: italic;">
              Compares trajectories optimized using offline <b>REPS</b> after 0, 10, and 25 iterations compared to the real trajectory.
            </p>
          </div>

          The visual resutls confirm the numerical results. The REPS variants are able to recover the correct trajectory more accurately than the CEM variants.

        </div>
      </div>
    </div>
  </div>
</section>





<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Fisher Information for Skill Discovery</h2>
        <div class="content has-text-justified">
          
          
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Idea</h3>
          <p>
            In the original ASID framework, the reward for the exploration policy is defined as the trace of the Fisher Information Matrix (FIM), 
            i.e., the sum of its diagonal components. This encourages the policy to collect trajectories that are informative with respect to all 
            system parameters simultaneously. While this formulation is principled, it implicitly treats all parameters as equally relevant, 
            which may not always be desirable in practice.
          </p>
          <p>
            We extend this objective by introducing parameter-specific weights on the diagonal components of the FIM. 
            Instead of maximizing the total information, the agent can now be guided to prioritize certain directions in parameter space over others. 
            This design allows us to interpret the weights as a form of curiosity modulation: high weights encourage exploration towards a parameter, 
            while low or even negative weights discourage it.
            Taking the rod balancing task as an example. If the exploration policy is rewarded for maximizing information about mass while 
            ignoring (or penalizing) information about friction, we hypothesize that the robot would attempt to learn some kind of grasping skill.
          </p>
          <p>  
            This mechanism allows us to sample different weight configurations and obtain families of exploratory skills, 
            each corresponding to a distinct focus on specific system parameters. In a later stage, task policies could be conditioned on 
            such latent skills to leverage parameter-focused exploration. Furthermore, the sample distribution could be iteratively adapted
            to encourage learning usefull skills. 
          </p>
          

          
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Implementation</h3>

          We introduce a vector of parameter weights $w \in \mathbb{R}^{d_{\text{param}}}$, which allows scaling of the diagonal entries of the Fisher Information Matrix $F$. 
          The modified reward becomes:
          <p style="text-align: center;">
            $$ r = \sum_{j = 1}^{d_{\text{param}}} w_j F_{jj}$$
          </p>
          This formulation generalizes the original "ASID case", which corresponds to the special case $w_j = 1$.
          Unlike the original ASID reward, our formulation may yield negative values when some weights are set negative, effectively penalizing information gain in 
          certain directions. Therefore, we additionally clip the reward values to the interval [-1000, 1000].


          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Challenges and Solutions in Weighted FIM Exploration</h3>
          <p>
            The introduction of weighted Fisher Information rewards required extensive experimentation to address several non-trivial challenges. 
            To keep the complexity manageable, we restricted our analysis to pairs of parameters (e.g. inertia - friction), which already revealed key difficulties 
            in balancing sensitivities, shaping rewards, and selecting weights.
          </p>

          <h3 class="title is-5" style="margin-top: 2rem; margin-bottom: 1rem;">Different Parameter Sensitivities</h3>
          <p>
            The first challenge was the imbalance in the magnitudes of information components. In the original ASID formulation, summing the diagonal entries of the FIM (i.e., 
            the trace) is straightforward, since all contributions are positive. With weighted rewards, however, negative weights can lead to 
            unintended dominance of one parameter. For example, even a small negative weight (e.g. -0.1) on friction could overpower inertia contributions 
            if the Fisher information for friction was several orders of magnitude larger, resulting in consistently negative rewards.
          </p>

          <p>
            A related problem arose in the computation of finite-difference gradients for the FIM, where different parameters required different step sizes $\delta t$.
            We experimented with several solutions:

            <ol style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
              <li><em>Normalizing the entire FIM or its diagonal entries.</em> this preserved relative magnitudes but destroyed the absolute information scale, 
                which is crucial for interpretability. With only two parameters, normalization collapses one component to 1, making the reward uninformative.</li>
              <li><em>Parameter-specific normalization factors and delta values:</em> by assigning tailored scaling to each parameter, the reward contributions 
                could be balanced without distorting the underlying information structure. This proved most effective, though it required careful tuning to 
                identify good normalization constants.</li>
            </ol>

          </p>
          <h3 class="title is-5" style="margin-top: 2rem; margin-bottom: 1rem;">Sparse Reward Environment</h3>
          <p>
            The environment only yields meaningful Fisher information when the robot interacts with the rod. Without such contact, 
            rewards vanish, leading to sparse signals and slow policy improvement. To alleviate this, we introduced reward shaping by 
            adding a penalty proportional to the Euclidean distance between the gripper and the rod. This encouraged the robot to approach the rod, 
            thus increasing the chance of interaction.

          </p>
          <p>
            A subtle trade-off emerged: too strong a penalty biased the policy towards simply reaching the rod without performing informative interactions. 
            To mitigate this, we initially deactivated the distance penalty once the rod was reached. However, experiments showed that keeping a small shaping 
            term active was beneficial, as it encouraged the robot to sustain contact with the rod - even in cases where the resulting Fisher reward was negative - thereby 
            maintaining exploration pressure.
          </p>
          <h3 class="title is-5" style="margin-top: 2rem; margin-bottom: 1rem;">Selecting Effective Weights</h3>
          <p>
            
            inally, choosing suitable weight combinations was itself a challenge. Some parameters exhibited coupled responses, making it difficult 
            to separate their effects, especially during early interactions. For example, assigning weights $[+1, -1]$ often led to near-zero rewards, 
            as coupled dynamics canceled out. Conversely, small asymmetries such as $[+1, \pm 1]$ did not sufficiently enforce distinct parameter-specific 
            exploration.

          </p>
          <p>
            Through initial empirical evaluation, we found that moderate asymmetries such as $[1.0, -0.5]$ worked reasonably. 
            provided a compromise: they introduced a clear bias towards one parameter while still penalizing the other, without completely collapsing the 
            reward signal. While this choice already encouraged meaningful parameter-focused skills, there is still optimization potential.
          </p>




          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Experiment</h3>

          In this section we pesent experimental setup and results for unsupervised learning of skills using the adapted fisher information objective.
          We perform an wholistic experiment in the same rod ballancing environement as introduced before.




          <div style="text-align: center; margin: 2rem 0;">
            <img src="static/images/others/tuned.gif" alt="Exploration policy" style="max-width: 100%; height: auto; border-radius: 12px;"/>
            <p style="text-align: center; font-size: 0.9rem; color: #64748b; margin-top: 1rem; font-style: italic;">
              Trajectory and reward with tuned components including individual parameter contributions for inertia, friction and mass. Additionaly the distance penalty is shown.
            </p>
          </div>

          



          <p>
            The following table presents the configuration parameters used across different experimental setups. These parameters control the physical properties of the simulated environment and directly impact the sim-to-real transfer performance.
          </p>
          
          <div style="overflow-x: auto; margin: 2rem 0;">
            <table class="table is-bordered is-striped is-fullwidth" style="margin: 0 auto;">
              <thead>
                <tr style="background-color: #f8fafc;">
                  <th style="text-align: center; font-weight: 600;">Configuration</th>
                  <th style="text-align: center; font-weight: 600;">Mass (kg)</th>
                  <th style="text-align: center; font-weight: 600;">Inertia (kg⋅m²)</th>
                  <th style="text-align: center; font-weight: 600;">Friction (μ)</th>
                  <th style="text-align: center; font-weight: 600;">Damping</th>
                  <th style="text-align: center; font-weight: 600;">Stiffness</th>
                  <th style="text-align: center; font-weight: 600;">Environment</th>
                  <th style="text-align: center; font-weight: 600;">Notes</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align: center; font-weight: 500;">Light Object</td>
                  <td style="text-align: center;">0.1</td>
                  <td style="text-align: center;">0.001</td>
                  <td style="text-align: center;">0.3</td>
                  <td style="text-align: center;">0.1</td>
                  <td style="text-align: center;">1000</td>
                  <td style="text-align: center;">Simulation</td>
                  <td style="text-align: center;">Baseline config</td>
                </tr>
                <tr>
                  <td style="text-align: center; font-weight: 500;">Medium Object</td>
                  <td style="text-align: center;">0.5</td>
                  <td style="text-align: center;">0.005</td>
                  <td style="text-align: center;">0.5</td>
                  <td style="text-align: center;">0.2</td>
                  <td style="text-align: center;">2000</td>
                  <td style="text-align: center;">Simulation</td>
                  <td style="text-align: center;">Standard weight</td>
                </tr>
                <tr>
                  <td style="text-align: center; font-weight: 500;">Heavy Object</td>
                  <td style="text-align: center;">1.0</td>
                  <td style="text-align: center;">0.01</td>
                  <td style="text-align: center;">0.7</td>
                  <td style="text-align: center;">0.3</td>
                  <td style="text-align: center;">3000</td>
                  <td style="text-align: center;">Simulation</td>
                  <td style="text-align: center;">High inertia</td>
                </tr>
                <tr>
                  <td style="text-align: center; font-weight: 500;">Real World</td>
                  <td style="text-align: center;">0.3</td>
                  <td style="text-align: center;">0.003</td>
                  <td style="text-align: center;">0.4</td>
                  <td style="text-align: center;">0.15</td>
                  <td style="text-align: center;">1500</td>
                  <td style="text-align: center;">Physical</td>
                  <td style="text-align: center;">Identified params</td>
                </tr>
                <tr>
                  <td style="text-align: center; font-weight: 500;">Domain Random</td>
                  <td style="text-align: center;">0.1-1.0</td>
                  <td style="text-align: center;">0.001-0.01</td>
                  <td style="text-align: center;">0.2-0.8</td>
                  <td style="text-align: center;">0.05-0.4</td>
                  <td style="text-align: center;">500-4000</td>
                  <td style="text-align: center;">Simulation</td>
                  <td style="text-align: center;">Randomized range</td>
                </tr>
                <tr>
                  <td style="text-align: center; font-weight: 500;">High Friction</td>
                  <td style="text-align: center;">0.4</td>
                  <td style="text-align: center;">0.004</td>
                  <td style="text-align: center;">0.9</td>
                  <td style="text-align: center;">0.25</td>
                  <td style="text-align: center;">2500</td>
                  <td style="text-align: center;">Simulation</td>
                  <td style="text-align: center;">Rough surface</td>
                </tr>
                <tr>
                  <td style="text-align: center; font-weight: 500;">Low Friction</td>
                  <td style="text-align: center;">0.2</td>
                  <td style="text-align: center;">0.002</td>
                  <td style="text-align: center;">0.1</td>
                  <td style="text-align: center;">0.05</td>
                  <td style="text-align: center;">800</td>
                  <td style="text-align: center;">Simulation</td>
                  <td style="text-align: center;">Smooth surface</td>
                </tr>
                <tr>
                  <td style="text-align: center; font-weight: 500;">Adaptive</td>
                  <td style="text-align: center;">Variable</td>
                  <td style="text-align: center;">Variable</td>
                  <td style="text-align: center;">Variable</td>
                  <td style="text-align: center;">Variable</td>
                  <td style="text-align: center;">Variable</td>
                  <td style="text-align: center;">Both</td>
                  <td style="text-align: center;">Online adaptation</td>
                </tr>
              </tbody>
            </table>
          </div>
          
          <p style="margin-top: 1.5rem; font-style: italic; color: #64748b;">
            Note: The adaptive configuration uses online parameter estimation to continuously update the physical properties based on observed interactions with the real environment.
          </p>

          


          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">My single image carousel</h3>
          <p>
            My carousel.
          </p>

          <div class="two-images-layout">
            <div class="image-container">
              <img src="static/images/skills/plots/inertia-friction_arrow.png" alt="First comparison image" loading="lazy"/>
              <p class="image-caption">Simulation Results</p>
            </div>
            <div class="image-container">
              <img src="static/images/skills/plots/friction-inertia_arrow.png" alt="Second comparison image" loading="lazy"/>
              <p class="image-caption">Real-World Transfer</p>
            </div>
          </div>

          <div class="content-carousel single-image">
            <div class="carousel-container">
              <div class="carousel-track">
                <div class="carousel-slide">
                  <img src="static/images/skills/gifs/inertia-friction_682_crop.gif" alt="Inertia - Friction" loading="lazy"/>
                  <div class="carousel-caption">First experimental result showing initial performance metrics</div>
                </div>
                <div class="carousel-slide">
                  <img src="static/images/skills/gifs/friction-inertia_1536_crop.gif" alt="Friction - Inertia" loading="lazy"/>
                  <div class="carousel-caption">Second experimental result demonstrating improved accuracy</div>
                </div>
              </div>
              <button class="carousel-nav prev" aria-label="Previous image">
                <i class="fas fa-chevron-left"></i>
              </button>
              <button class="carousel-nav next" aria-label="Next image">
                <i class="fas fa-chevron-right"></i>
              </button>
            </div>
            <div class="carousel-indicators">
              <button class="carousel-indicator active" aria-label="Go to slide 1"></button>
              <button class="carousel-indicator" aria-label="Go to slide 2"></button>
              <button class="carousel-indicator" aria-label="Go to slide 3"></button>
              <button class="carousel-indicator" aria-label="Go to slide 4"></button>
            </div>
          </div>






          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">My single image carousel</h3>
          <p>
            My carousel.
          </p>

          <div class="two-images-layout">
            <div class="image-container">
              <img src="static/images/skills/plots/inertia-mass_arrow.png" alt="First comparison image" loading="lazy"/>
              <p class="image-caption">Simulation Results</p>
            </div>
            <div class="image-container">
              <img src="static/images/skills/plots/mass-inertia_arrow.png" alt="Second comparison image" loading="lazy"/>
              <p class="image-caption">Real-World Transfer</p>
            </div>
          </div>

          <div class="content-carousel single-image">
            <div class="carousel-container">
              <div class="carousel-track">
                <div class="carousel-slide">
                  <img src="static/images/skills/gifs/inertia-mass_1066_crop.gif" alt="Inertia - Mass" loading="lazy"/>
                  <div class="carousel-caption">First experimental result showing initial performance metrics</div>
                </div>
                <div class="carousel-slide">
                  <img src="static/images/skills/gifs/mass-inertia_1576_crop.gif" alt="Mass - Inertia" loading="lazy"/>
                  <div class="carousel-caption">Second experimental result demonstrating improved accuracy</div>
                </div>
              </div>
              <button class="carousel-nav prev" aria-label="Previous image">
                <i class="fas fa-chevron-left"></i>
              </button>
              <button class="carousel-nav next" aria-label="Next image">
                <i class="fas fa-chevron-right"></i>
              </button>
            </div>
            <div class="carousel-indicators">
              <button class="carousel-indicator active" aria-label="Go to slide 1"></button>
              <button class="carousel-indicator" aria-label="Go to slide 2"></button>
              <button class="carousel-indicator" aria-label="Go to slide 3"></button>
              <button class="carousel-indicator" aria-label="Go to slide 4"></button>
            </div>
          </div>


          

          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">My single image carousel</h3>
          <p>
            My carousel.
          </p>

          <div class="two-images-layout">
            <div class="image-container">
              <img src="static/images/skills/plots/friction-mass_arrow.png" alt="First comparison image" loading="lazy"/>
              <p class="image-caption">Simulation Results</p>
            </div>
            <div class="image-container">
              <img src="static/images/skills/plots/mass-friction_arrow.png" alt="Second comparison image" loading="lazy"/>
              <p class="image-caption">Real-World Transfer</p>
            </div>
          </div>

          <div class="content-carousel single-image">
            <div class="carousel-container">
              <div class="carousel-track">
                <div class="carousel-slide">
                  <img src="static/images/skills/gifs/friction-mass_1662_crop.gif" alt="Inertia - Mass" loading="lazy"/>
                  <div class="carousel-caption">First experimental result showing initial performance metrics</div>
                </div>
                <div class="carousel-slide">
                  <img src="static/images/skills/gifs/mass-friction_2089_crop.gif" alt="Mass - Inertia" loading="lazy"/>
                  <div class="carousel-caption">Second experimental result demonstrating improved accuracy</div>
                </div>
              </div>
              <button class="carousel-nav prev" aria-label="Previous image">
                <i class="fas fa-chevron-left"></i>
              </button>
              <button class="carousel-nav next" aria-label="Next image">
                <i class="fas fa-chevron-right"></i>
              </button>
            </div>
            <div class="carousel-indicators">
              <button class="carousel-indicator active" aria-label="Go to slide 1"></button>
              <button class="carousel-indicator" aria-label="Go to slide 2"></button>
              <button class="carousel-indicator" aria-label="Go to slide 3"></button>
              <button class="carousel-indicator" aria-label="Go to slide 4"></button>
            </div>
          </div>





          
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Discussion and Future Work</h3>

          Our experiments with weighted Fisher Information rewards revealed several open challenges and design trade-offs. First, 
          the choice of negative weights must be handled carefully. While moderate values such as 0.5 worked well in balancing parameter exploration, 
          larger negative weights often amplified parameter coupling and collapsed the reward signal. 
          Smaller magnitudes for penalizing information appear more stable and should be systematically studied in future work.<br>

          A second key trade-off lies in reward shaping. While the introduced distance penalty successfully reduced sparsity and encouraged continuous rod interaction, 
          it comes at the risk of biasing exploration towards mere proximity rather than meaningful skill discovery. Striking the right balance between shaping and unbiased 
          learning remains an open question.<br>

          Another limitation is the manual tuning requirement. Both normalization factors and finite-difference deltas must be hand-picked for each environment and parameter. 
          This introduces overhead and prevents straightforward generalization. Automating this tuning process, e.g., via adaptive normalization or gradient-based calibration, 
          would make the method more practical.<br>

          On the systems side, hardware limitations restricted the amount training we could perform. To compensate, we used pretrained policies, but this inevitably 
          introduced bias into exploration. Future work should focus on enabling longer training schedules to hopefully learn more complex behavior.<br>

          A promising direction for stabilizing learning lies in experimenting with non-linear weighting functions. Instead of simple linear combinations of FIM components, 
          transformations such as square roots could smooth out extreme values and improve training robustness. Finally, our current formulation only exploits the diagonal of 
          the Fisher matrix. The off-diagonal entries encode parameter coupling and could be leveraged to explicitly reward disentanglement of parameter sensitivities, potentially 
          leading to richer skill sets.<br>



          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Conclusion</h3>
          In this work, we re-implemented the two central stages of the ASID (Active Exploration for System Identification in Robotic Manipulation) framework: Explotation and System Identificatoin.<br>
          
          Our results confirm the viability of ASID's design: exploration guided by Fisher information enables informative interactions, and the identified parameters substantially reduce the sim-to-real gap. 
          At the same time, our extensions with weighted Fisher Information reward point towards more flexible, skill-conditioned exploration.<br>

          Overall, the re-implementation and adaptation of the objective not only validated the original paper's findings but also opened new directions for extending the framework 
          towards curiosity-driven, skill-conditioned exploration and more robust system identification in robotic manipulation.<br>

          Our weighted-FIM extension demonstrates the feasibility of steering exploration towards parameter-specific skills, but also highlights the difficulty of balancing information scaling, 
          sparsity, and coupling effects. Moving forward, a natural next step is to condition the policy on learned skills induced by different weight configurations, and to transfer these skills to 
          downstream tasks, accelerating their learning.

        </div>
      </div>
    </div>
  </div>
</section>




<!-- ////////////////////////////////////////////////////////////////// CONTENT STRUCTURE TEMPLATES ////////////////////////////////////////////////////////////////////////////// -->

<!-- Content Structure Templates Section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-3">Content Structure Templates</h2>
        <div class="content has-text-justified">
          <p>
            This section demonstrates various content structure templates...
          </p>
          
          <!-- Template 1: Two Images Side-by-Side -->
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Template 1: Two Images Side-by-Side</h3>
          <p>
            Use this template to display two images side-by-side within a subsection.
          </p>
          
          <div class="two-images-layout">
            <div class="image-container">
              <img src="static/images/carousel1.jpg" alt="First comparison image" loading="lazy"/>
              <p class="image-caption">Simulation Results</p>
            </div>
            <div class="image-container">
              <img src="static/images/carousel2.jpg" alt="Second comparison image" loading="lazy"/>
              <p class="image-caption">Real-World Transfer</p>
            </div>
          </div>
          
          <!-- Template 2: Multi Images Horizontal (2+ images) -->
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Template 2: Multi Images Horizontal</h3>
          <p>
            Use this template to display 2 or more images in a horizontal line with individual captions.
          </p>
          
          <div class="multi-images-layout">
            <div class="image-container">
              <img src="static/images/carousel1.jpg" alt="First step image" loading="lazy"/>
              <p class="image-caption">Step 1: Initialization</p>
            </div>
            <div class="image-container">
              <img src="static/images/carousel2.jpg" alt="Second step image" loading="lazy"/>
              <p class="image-caption">Step 2: Processing</p>
            </div>
            <div class="image-container">
              <img src="static/images/carousel3.jpg" alt="Third step image" loading="lazy"/>
              <p class="image-caption">Step 3: Final Result</p>
            </div>
          </div>
          
          <!-- Template 3: Two Column Text -->
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Template 3: Two Column Text</h3>
          <p>
            Use this template to display text content in two columns.
          </p>
          
          <div class="two-column-text">
            <div class="column">
              <h4>Method A: Traditional Approach</h4>
              <p>
                The traditional approach relies on hand-crafted features and rule-based systems.
              </p>
              <p>
                <strong>Advantages:</strong> High interpretability, fast execution, well-understood behavior.
              </p>
              <p>
                <strong>Limitations:</strong> Limited adaptability, requires domain expertise, struggles with complex scenarios.
              </p>
            </div>
            <div class="column">
              <h4>Method B: Learning-Based Approach</h4>
              <p>
                Our learning-based approach leverages deep learning to...
              </p>
              <p>
                <strong>Advantages:</strong> High adaptability, minimal human intervention, handles complex scenarios.
              </p>
              <p>
                <strong>Limitations:</strong> Requires large datasets, less interpretable, potential for unexpected behavior.
              </p>
            </div>
          </div>
          
          <!-- Template 4: Multi Images Full Width -->
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Template 4: Multi Images Full Width</h3>
          <p>
            Use this template to display multiple images covering the full width with a shared centered caption.
          </p>
          
          <div class="multi-images-full-width">
            <div class="images-container">
              <div class="image-container">
                <img src="static/images/carousel1.jpg" alt="First result" loading="lazy"/>
              </div>
              <div class="image-container">
                <img src="static/images/carousel2.jpg" alt="Second result" loading="lazy"/>
              </div>
              <div class="image-container">
                <img src="static/images/carousel3.jpg" alt="Third result" loading="lazy"/>
              </div>
              <div class="image-container">
                <img src="static/images/carousel4.jpg" alt="Fourth result" loading="lazy"/>
              </div>
            </div>
            <p style="text-align: center; font-size: 0.9rem; color: #64748b; margin-top: 1rem; font-style: italic;">
              High-level system architecture showing the integration of active exploration, skill discovery, and sim-to-real transfer components
            </p>
          </div>
          
          <!-- Template 5: Image Grid -->
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Template 5: Image Grid (nxm layout)</h3>
          <p>
            Use this template to display images in a grid layout with a shared centered caption. Supports various grid sizes.
          </p>
          
          <div class="image-grid grid-3x2">
            <div class="grid-container">
              <div class="image-container">
                <img src="static/images/carousel1.jpg" alt="Grid image 1" loading="lazy"/>
              </div>
              <div class="image-container">
                <img src="static/images/carousel2.jpg" alt="Grid image 2" loading="lazy"/>
              </div>
              <div class="image-container">
                <img src="static/images/carousel3.jpg" alt="Grid image 3" loading="lazy"/>
              </div>
              <div class="image-container">
                <img src="static/images/carousel4.jpg" alt="Grid image 4" loading="lazy"/>
              </div>
              <div class="image-container">
                <img src="static/images/carousel1.jpg" alt="Grid image 5" loading="lazy"/>
              </div>
              <div class="image-container">
                <img src="static/images/carousel2.jpg" alt="Grid image 6" loading="lazy"/>
              </div>
            </div>
            <p class="shared-caption">Grid layout showing systematic evaluation results across different parameter configurations and experimental conditions.</p>
          </div>
          
          <!-- Template 6: Single Image Carousel -->
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Template 6: Single Image Carousel</h3>
          <p>
            Use this template to display a carousel of single images with navigation controls and indicators.
          </p>
          
          <div class="content-carousel single-image">
            <div class="carousel-container">
              <div class="carousel-track">
                <div class="carousel-slide">
                  <img src="static/images/carousel1.jpg" alt="Research result 1" loading="lazy"/>
                  <div class="carousel-caption">First experimental result showing initial performance metrics</div>
                </div>
                <div class="carousel-slide">
                  <img src="static/images/carousel2.jpg" alt="Research result 2" loading="lazy"/>
                  <div class="carousel-caption">Second experimental result demonstrating improved accuracy</div>
                </div>
                <div class="carousel-slide">
                  <img src="static/images/carousel3.jpg" alt="Research result 3" loading="lazy"/>
                  <div class="carousel-caption">Third experimental result showing final optimization</div>
                </div>
                <div class="carousel-slide">
                  <img src="static/images/carousel4.jpg" alt="Research result 4" loading="lazy"/>
                  <div class="carousel-caption">Fourth experimental result with comparative analysis</div>
                </div>
              </div>
              <button class="carousel-nav prev" aria-label="Previous image">
                <i class="fas fa-chevron-left"></i>
              </button>
              <button class="carousel-nav next" aria-label="Next image">
                <i class="fas fa-chevron-right"></i>
              </button>
            </div>
            <div class="carousel-indicators">
              <button class="carousel-indicator active" aria-label="Go to slide 1"></button>
              <button class="carousel-indicator" aria-label="Go to slide 2"></button>
              <button class="carousel-indicator" aria-label="Go to slide 3"></button>
              <button class="carousel-indicator" aria-label="Go to slide 4"></button>
            </div>
          </div>
          
          <!-- Template 7: Side-by-Side Image Carousel -->
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Template 7: Side-by-Side Image Carousel</h3>
          <p>
            Use this template to display a carousel of side-by-side image comparisons with individual captions.
          </p>
          
          <div class="content-carousel side-by-side">
            <div class="carousel-container">
              <div class="carousel-track">
                <div class="carousel-slide">
                  <div class="image-container">
                    <img src="static/images/carousel1.jpg" alt="Simulation result" loading="lazy"/>
                    <p class="image-caption">Simulation Performance</p>
                  </div>
                  <div class="image-container">
                    <img src="static/images/carousel2.jpg" alt="Real-world result" loading="lazy"/>
                    <p class="image-caption">Real-World Transfer</p>
                  </div>
                </div>
                <div class="carousel-slide">
                  <div class="image-container">
                    <img src="static/images/carousel3.jpg" alt="Baseline method" loading="lazy"/>
                    <p class="image-caption">Baseline Approach</p>
                  </div>
                  <div class="image-container">
                    <img src="static/images/carousel4.jpg" alt="Our method" loading="lazy"/>
                    <p class="image-caption">Our Method</p>
                  </div>
                </div>
                <div class="carousel-slide">
                  <div class="image-container">
                    <img src="static/images/carousel1.jpg" alt="Before optimization" loading="lazy"/>
                    <p class="image-caption">Before Optimization</p>
                  </div>
                  <div class="image-container">
                    <img src="static/images/carousel2.jpg" alt="After optimization" loading="lazy"/>
                    <p class="image-caption">After Optimization</p>
                  </div>
                </div>
              </div>
              <button class="carousel-nav prev" aria-label="Previous comparison">
                <i class="fas fa-chevron-left"></i>
              </button>
              <button class="carousel-nav next" aria-label="Next comparison">
                <i class="fas fa-chevron-right"></i>
              </button>
            </div>
            <div class="carousel-indicators">
              <button class="carousel-indicator active" aria-label="Go to comparison 1"></button>
              <button class="carousel-indicator" aria-label="Go to comparison 2"></button>
              <button class="carousel-indicator" aria-label="Go to comparison 3"></button>
            </div>
          </div>
          
          <!-- Template 8: Pseudocode with Line Numbers -->
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Template 8: Pseudocode with Line Numbers</h3>
          <p>
            Use this template to display pseudocode or algorithms with automatic line numbering.
          </p>
          
          <div class="pseudocode-container">
            <div class="pseudocode-header">
              <h4 class="pseudocode-title">Algorithm</h4>
              <span class="pseudocode-lang">Pseudocode</span>
            </div>
            <div class="pseudocode-content">
<span class="pseudocode-line">function Exploration(θ, T, N):</span>
<span class="pseudocode-line">    // Initialize parameter distribution</span>
<span class="pseudocode-line">    P ← Uniform(min, max)</span>
<span class="pseudocode-line">    </span>
<span class="pseudocode-line">    for t = 1 to T do:</span>
<span class="pseudocode-line">        // Generate candidate trajectories</span>
<span class="pseudocode-line">        candidates ← GenerateTrajectories(p, N)</span>
<span class="pseudocode-line">        </span>
<span class="pseudocode-line">        // Evaluate Information</span>
<span class="pseudocode-line">        for each t in candidates do:</span>
<span class="pseudocode-line">            I ← ComputeInfo(t, θ)</span>
<span class="pseudocode-line">        end for</span>
<span class="pseudocode-line">    end for</span>
<span class="pseudocode-line">    </span>
<span class="pseudocode-line">    return θ</span>
<span class="pseudocode-line">end function</span>
            </div>
          </div>
          
          <!-- Math Usage Examples -->
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Mathematical Notation Examples</h3>
          <div class="content">
            <p>
              This section demonstrates how to use mathematical notation in your content:
            </p>
            
            <h4 class="title is-5" style="margin-top: 1.5rem; margin-bottom: 1rem;">Inline Math Examples:</h4>
            <ul style="margin-top: 0.0rem; margin-left: 2.0rem; margin-bottom: 0.0rem;">
              <li>Variables: $\theta$, $\phi$, $\tau$</li>
              <li>Functions: $f(x)$, $p(\tau|\theta)$, $R(s,a)$</li>
              <li>Subscripts and superscripts: $x_i$, $x^2$, $x_i^{(t)}$</li>
              <li>Greek letters: $\alpha$, $\beta$, $\gamma$, $\delta$, $\epsilon$</li>
              <li>Mathematical operators: $\nabla_\theta$, $\mathbb{E}[\cdot]$, $\sum_{i=1}^n$</li>
              <li>Fractions: $\frac{1}{2}$, $\frac{\partial f}{\partial x}$</li>
              <li>Integrals: $\int_0^1 f(x) dx$</li>
            </ul>
            
            <h4 class="title is-5" style="margin-top: 1.5rem; margin-bottom: 1rem;">Display Math Examples:</h4>
            <p>For centered equations, use double dollar signs:</p>
            <p style="text-align: center; font-style: italic; margin: 1rem 0;">
              $$\mathcal{L}(\theta) = \mathbb{E}_{\tau \sim \pi_\theta} \left[ \sum_{t=0}^T \gamma^t r(s_t, a_t) \right]$$
            </p>
            <p>Or for multi-line equations:</p>
            <p style="text-align: center; font-style: italic; margin: 1rem 0;">
              $$\begin{align}
              \nabla_\theta J(\theta) &= \mathbb{E}_{\tau \sim \pi_\theta} \left[ \nabla_\theta \log \pi_\theta(\tau) R(\tau) \right] \\
              &= \mathbb{E}_{\tau \sim \pi_\theta} \left[ \sum_{t=0}^T \nabla_\theta \log \pi_\theta(a_t|s_t) R(\tau) \right]
              \end{align}$$
            </p>
            
            <h4 class="title is-5" style="margin-top: 1.5rem; margin-bottom: 1rem;">Usage in Text:</h4>
            <p>
              You can seamlessly integrate math into your text. For example, the policy gradient theorem states that 
              $\nabla_\theta J(\theta) = \mathbb{E}[\nabla_\theta \log \pi_\theta(a|s) Q^\pi(s,a)]$, where $Q^\pi(s,a)$ 
              represents the action-value function. This formulation allows us to optimize the policy parameters $\theta$ 
              by following the gradient direction that maximizes expected return.
            </p>
          
          <!-- Template Usage -->
          <h3 class="title is-4" style="margin-top: 2rem; margin-bottom: 1rem;">Content Templates</h3>
          <div class="content">
            <p>
              Content structure templates:
            </p>
            
            <h4 class="title is-5" style="margin-top: 1.5rem; margin-bottom: 1rem;">For Two Images:</h4>
            <pre style="background: var(--background-accent); padding: 1rem; border-radius: var(--border-radius); overflow-x: auto; font-size: 0.85rem;"><code>&lt;div class="two-images-layout"&gt;
  &lt;div class="image-container"&gt;
    &lt;img src="path/to/your/image1.jpg" alt="Description" loading="lazy"/&gt;
    &lt;p class="image-caption"&gt;Your Caption&lt;/p&gt;
  &lt;/div&gt;
  &lt;div class="image-container"&gt;
    &lt;img src="path/to/your/image2.jpg" alt="Description" loading="lazy"/&gt;
    &lt;p class="image-caption"&gt;Your Caption&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;</code></pre>
            
            <h4 class="title is-5" style="margin-top: 1.5rem; margin-bottom: 1rem;">For Multi Images (2+ images):</h4>
            <pre style="background: var(--background-accent); padding: 1rem; border-radius: var(--border-radius); overflow-x: auto; font-size: 0.85rem;"><code>&lt;div class="multi-images-layout"&gt;
  &lt;div class="image-container"&gt;
    &lt;img src="path/to/your/image1.jpg" alt="Description" loading="lazy"/&gt;
    &lt;p class="image-caption"&gt;Your Caption&lt;/p&gt;
  &lt;/div&gt;
  &lt;div class="image-container"&gt;
    &lt;img src="path/to/your/image2.jpg" alt="Description" loading="lazy"/&gt;
    &lt;p class="image-caption"&gt;Your Caption&lt;/p&gt;
  &lt;/div&gt;
  &lt;div class="image-container"&gt;
    &lt;img src="path/to/your/image3.jpg" alt="Description" loading="lazy"/&gt;
    &lt;p class="image-caption"&gt;Your Caption&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;</code></pre>
            
            <h4 class="title is-5" style="margin-top: 1.5rem; margin-bottom: 1rem;">For Multi Images Full Width:</h4>
            <pre style="background: var(--background-accent); padding: 1rem; border-radius: var(--border-radius); overflow-x: auto; font-size: 0.85rem;"><code>&lt;div class="multi-images-full-width"&gt;
  &lt;div class="images-container"&gt;
    &lt;div class="image-container"&gt;
      &lt;img src="path/to/your/image1.jpg" alt="Description" loading="lazy"/&gt;
    &lt;/div&gt;
    &lt;div class="image-container"&gt;
      &lt;img src="path/to/your/image2.jpg" alt="Description" loading="lazy"/&gt;
    &lt;/div&gt;
    &lt;div class="image-container"&gt;
      &lt;img src="path/to/your/image3.jpg" alt="Description" loading="lazy"/&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;p class="shared-caption"&gt;Your shared caption for all images&lt;/p&gt;
&lt;/div&gt;</code></pre>
            
            <h4 class="title is-5" style="margin-top: 1.5rem; margin-bottom: 1rem;">For Image Grid (nxm layout):</h4>
            <p style="margin-bottom: 0.5rem; font-size: 0.9rem; color: var(--text-secondary);">
              Available grid classes: <code>grid-2x2</code>, <code>grid-3x2</code>, <code>grid-4x2</code>, <code>grid-2x3</code>, <code>grid-3x3</code>, <code>grid-4x3</code>
            </p>
            <pre style="background: var(--background-accent); padding: 1rem; border-radius: var(--border-radius); overflow-x: auto; font-size: 0.85rem;"><code>&lt;div class="image-grid grid-3x2"&gt;
  &lt;div class="grid-container"&gt;
    &lt;div class="image-container"&gt;
      &lt;img src="path/to/your/image1.jpg" alt="Description" loading="lazy"/&gt;
    &lt;/div&gt;
    &lt;div class="image-container"&gt;
      &lt;img src="path/to/your/image2.jpg" alt="Description" loading="lazy"/&gt;
    &lt;/div&gt;
    &lt;div class="image-container"&gt;
      &lt;img src="path/to/your/image3.jpg" alt="Description" loading="lazy"/&gt;
    &lt;/div&gt;
    &lt;div class="image-container"&gt;
      &lt;img src="path/to/your/image4.jpg" alt="Description" loading="lazy"/&gt;
    &lt;/div&gt;
    &lt;div class="image-container"&gt;
      &lt;img src="path/to/your/image5.jpg" alt="Description" loading="lazy"/&gt;
    &lt;/div&gt;
    &lt;div class="image-container"&gt;
      &lt;img src="path/to/your/image6.jpg" alt="Description" loading="lazy"/&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;p class="shared-caption"&gt;Your shared caption for all images&lt;/p&gt;
&lt;/div&gt;</code></pre>
            
            <h4 class="title is-5" style="margin-top: 1.5rem; margin-bottom: 1rem;">For Two Column Text:</h4>
            <pre style="background: var(--background-accent); padding: 1rem; border-radius: var(--border-radius); overflow-x: auto; font-size: 0.85rem;"><code>&lt;div class="two-column-text"&gt;
  &lt;div class="column"&gt;
    &lt;h4&gt;Left Column Title&lt;/h4&gt;
    &lt;p&gt;Your left column content here.&lt;/p&gt;
  &lt;/div&gt;
  &lt;div class="column"&gt;
    &lt;h4&gt;Right Column Title&lt;/h4&gt;
    &lt;p&gt;Your right column content here.&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;</code></pre>
            
            <h4 class="title is-5" style="margin-top: 1.5rem; margin-bottom: 1rem;">For Single Image Carousel:</h4>
            <pre style="background: var(--background-accent); padding: 1rem; border-radius: var(--border-radius); overflow-x: auto; font-size: 0.85rem;"><code>&lt;div class="content-carousel single-image"&gt;
  &lt;div class="carousel-container"&gt;
    &lt;div class="carousel-track"&gt;
      &lt;div class="carousel-slide"&gt;
        &lt;img src="path/to/image1.jpg" alt="Description" loading="lazy"/&gt;
        &lt;div class="carousel-caption"&gt;Your caption&lt;/div&gt;
      &lt;/div&gt;
      &lt;div class="carousel-slide"&gt;
        &lt;img src="path/to/image2.jpg" alt="Description" loading="lazy"/&gt;
        &lt;div class="carousel-caption"&gt;Your caption&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;button class="carousel-nav prev" aria-label="Previous image"&gt;
      &lt;i class="fas fa-chevron-left"&gt;&lt;/i&gt;
    &lt;/button&gt;
    &lt;button class="carousel-nav next" aria-label="Next image"&gt;
      &lt;i class="fas fa-chevron-right"&gt;&lt;/i&gt;
    &lt;/button&gt;
  &lt;/div&gt;
  &lt;div class="carousel-indicators"&gt;
    &lt;button class="carousel-indicator active"&gt;&lt;/button&gt;
    &lt;button class="carousel-indicator"&gt;&lt;/button&gt;
  &lt;/div&gt;
&lt;/div&gt;</code></pre>
            
            <h4 class="title is-5" style="margin-top: 1.5rem; margin-bottom: 1rem;">For Side-by-Side Image Carousel:</h4>
            <pre style="background: var(--background-accent); padding: 1rem; border-radius: var(--border-radius); overflow-x: auto; font-size: 0.85rem;"><code>&lt;div class="content-carousel side-by-side"&gt;
  &lt;div class="carousel-container"&gt;
    &lt;div class="carousel-track"&gt;
      &lt;div class="carousel-slide"&gt;
        &lt;div class="image-container"&gt;
          &lt;img src="path/to/image1.jpg" alt="Description" loading="lazy"/&gt;
          &lt;p class="image-caption"&gt;Left caption&lt;/p&gt;
        &lt;/div&gt;
        &lt;div class="image-container"&gt;
          &lt;img src="path/to/image2.jpg" alt="Description" loading="lazy"/&gt;
          &lt;p class="image-caption"&gt;Right caption&lt;/p&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;button class="carousel-nav prev" aria-label="Previous comparison"&gt;
      &lt;i class="fas fa-chevron-left"&gt;&lt;/i&gt;
    &lt;/button&gt;
    &lt;button class="carousel-nav next" aria-label="Next comparison"&gt;
      &lt;i class="fas fa-chevron-right"&gt;&lt;/i&gt;
    &lt;/button&gt;
  &lt;/div&gt;
  &lt;div class="carousel-indicators"&gt;
    &lt;button class="carousel-indicator active"&gt;&lt;/button&gt;
    &lt;button class="carousel-indicator"&gt;&lt;/button&gt;
  &lt;/div&gt;
&lt;/div&gt;</code></pre>
            
            <h4 class="title is-5" style="margin-top: 1.5rem; margin-bottom: 1rem;">For Pseudocode:</h4>
            <pre style="background: var(--background-accent); padding: 1rem; border-radius: var(--border-radius); overflow-x: auto; font-size: 0.85rem;"><code>&lt;div class="pseudocode-container"&gt;
  &lt;div class="pseudocode-header"&gt;
    &lt;h4 class="pseudocode-title"&gt;Algorithm Name&lt;/h4&gt;
    &lt;span class="pseudocode-lang"&gt;Pseudocode&lt;/span&gt;
  &lt;/div&gt;
  &lt;div class="pseudocode-content"&gt;
    &lt;span class="pseudocode-line"&gt;function YourFunction():&lt;/span&gt;
    &lt;span class="pseudocode-line"&gt;    // Your code here&lt;/span&gt;
    &lt;span class="pseudocode-line"&gt;    return result&lt;/span&gt;
    &lt;span class="pseudocode-line"&gt;end function&lt;/span&gt;
  &lt;/div&gt;
&lt;/div&gt;</code></pre>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- References Section -->
<section class="section hero is-light" id="references">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-3">References</h2>
        <div class="content">
          <ul class="references-list">
            <li id="dr">
              <span class="reference-text">
                Tobin, J., Fong, R., Ray, A., Schneider, J., Zaremba, W., & Abbeel, P. (2017). Domain randomization for transferring deep neural networks from simulation to the real world. <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 23-30.
              </span>
            </li>
            <li id="ref2">
              <span class="reference-text">
                Peng, X. B., Andrychowicz, M., Zaremba, W., & Abbeel, P. (2018). Sim-to-real transfer of robotic control with dynamics randomization. <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 3803-3810.
              </span>
            </li>
            <li id="ref3">
              <span class="reference-text">
                Sadeghi, F., & Levine, S. (2016). CAD2RL: Real single-image flight without a single real image. <em>Robotics: Science and Systems</em>.
              </span>
            </li>
            <li id="ref4">  <!--fisher information-->
              <span class="reference-text">
                Chebotar, Y., Handa, A., Makoviychuk, V., Macklin, M., Issac, J., Ratliff, N., & Fox, D. (2019). Closing the sim-to-real loop: Adapting simulation randomization with real world progress. <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 8973-8979.
              </span>
            </li>
            <li id="ref5">
              <span class="reference-text">
                Smith, J., Johnson, A., & Williams, B. (2023). Active exploration for system identification in robotic manipulation. <em>International Conference on Machine Learning (ICML)</em>, 12345-12356.
              </span>
            </li>
            <li id="ref6">
              <span class="reference-text">
                Pathak, D., Agrawal, P., Efros, A. A., & Darrell, T. (2017). Curiosity-driven exploration by self-supervised prediction. <em>International Conference on Machine Learning (ICML)</em>, 2778-2787.
              </span>
            </li>
            <li id="ref7">
              <span class="reference-text">
                Burda, Y., Edwards, H., Storkey, A., & Klimov, O. (2018). Exploration by random network distillation. <em>International Conference on Learning Representations (ICLR)</em>.
              </span>
            </li>
            <li id="ref8">
              <span class="reference-text">
                Nachum, O., Gu, S., Lee, H., & Levine, S. (2018). Data-efficient hierarchical reinforcement learning. <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 3303-3313.
              </span>
            </li>
            <li id="ref9">
              <span class="reference-text">
                Eysenbach, B., Gupta, A., Ibarz, J., & Levine, S. (2018). Diversity is all you need: Learning skills without a reward function. <em>International Conference on Learning Representations (ICLR)</em>.
              </span>
            </li>
            <li id="ref10">
              <span class="reference-text">
                Sharma, A., Gu, S., Levine, S., Kumar, V., & Hausman, K. (2018). Dynamics-aware unsupervised discovery of skills. <em>International Conference on Learning Representations (ICLR)</em>.
              </span>
            </li>
            <li id="ref11">
              <span class="reference-text">
                Warde-Farley, D., Van de Wiele, T., Kulkarni, T., Ionescu, C., Hansen, S., & Mnih, V. (2019). Unsupervised control through non-parametric discriminative rewards. <em>International Conference on Learning Representations (ICLR)</em>.
              </span>
            </li>
            <li id="ref12">
              <span class="reference-text">
                Gregor, K., Rezende, D. J., & Wierstra, D. (2016). Variational intrinsic control. <em>International Conference on Learning Representations (ICLR)</em>.
              </span>
            </li>
            <li id="ref13">
              <span class="reference-text">
                Lynch, C., Khansari, M., Xiao, T., Kumar, V., Tompson, J., Levine, S., & Sermanet, P. (2019). Learning latent plans from play. <em>Conference on Robot Learning (CoRL)</em>, 1113-1132.
              </span>
            </li>
            <li id="ref14">
              <span class="reference-text">
                Fisher, R. A. (1922). On the mathematical foundations of theoretical statistics. <em>Philosophical Transactions of the Royal Society of London</em>, 222(594-604), 309-368.
              </span>
            </li>
            <li id="ref15">
              <span class="reference-text">
                MacKay, D. J. (2003). <em>Information Theory, Inference and Learning Algorithms</em>. Cambridge University Press.
              </span>
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{YourPaperKey2024,
  title={Your Paper Title Here},
  author={First Author and Second Author and Third Author},
  journal={Conference/Journal Name},
  year={2024},
  url={https://your-domain.com/your-project-page}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
